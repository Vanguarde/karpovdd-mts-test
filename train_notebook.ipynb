{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e02b120-e764-4765-a64b-e410d372e8e5",
   "metadata": {},
   "source": [
    "Используемые ресурсы: 32gb RAM, i7-13700k, rtx4070 12gb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a557925e-d021-4e09-9bc6-e2405f2250ee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Baseline (tiny BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df833ef-d770-4681-a857-b8e1f037bf18",
   "metadata": {},
   "source": [
    "Baseline - rubert-tiny для получения первичных метрик. В качестве метрик буду смотреть на следующие:  \n",
    "f1 macro/micro/weighted  \n",
    "accuracy  \n",
    "\n",
    "В данном случае важно посмотреть в первую очередь на f1 macro и f1 микро. Первая будет проседать в случае сильно плохого качества на отдельных классах. Вторая покажет как в целом без относительно баланса модель дает предсказания.\n",
    "\n",
    "Разбиения train/test/val оставил базовыми."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021c61bf-967d-4a13-add3-4a6add102181",
   "metadata": {},
   "source": [
    "Для быстроты использую transformers, так как задача базовая"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cafc4fe1-031e-459c-b41c-35114caac087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd2f307d-7563-460b-9f6e-19725c69cadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"AmazonScience/massive\", \"ru-RU\").select_columns(['utt', 'intent'])\n",
    "dataset = dataset.rename_column(\"utt\", \"text\")\n",
    "dataset = dataset.rename_column(\"intent\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f190001-2c18-4eaf-83d5-702372c4b0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = len(dataset[\"train\"].features['label'].names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa2d42d6-40d7-4c19-a2d0-e92907818211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cfd7af1-fb1c-49d2-8561-73b683655626",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "roc_auc = evaluate.load(\"roc_auc\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    \n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    # probabilities = nn.functional.softmax(torch.tensor(logits), dim=1)[:,1]\n",
    "\n",
    "    f1_m = f1.compute(predictions=predictions, references=labels, average='macro')[\"f1\"]\n",
    "\n",
    "    f1_micro = f1.compute(predictions=predictions, references=labels, average='micro')[\"f1\"]\n",
    "\n",
    "    f1_w = f1.compute(predictions=predictions, references=labels, average='weighted')[\"f1\"]\n",
    "    \n",
    "    accuracy_m = accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    \n",
    "    return {\"f1_macro\": f1_m,\n",
    "            \"f1_micro\": f1_micro, \n",
    "            \"f1_weighted\": f1_w,\n",
    "            \"accuracy\": accuracy_m}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9e069a7-db97-4fae-89b6-36120337aadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "BATCH_SIZE = 64\n",
    "N_EPOCHS = 10\n",
    "MODEL_NAME = 'cointegrated/rubert-tiny2'\n",
    "LR = 5e-05\n",
    "EXPERIMENT_NAME = 'first_step'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd13dd8a-fac2-4063-9a1a-f24ccb848717",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True, model_max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85fe6cb6-46d5-4a4a-bcae-1c5c04045f86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda x: tokenizer(x['text'], truncation=True, padding='max_length'), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3eda4762-7ba0-4795-b590-1f8ade8945d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1800' max='1800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1800/1800 07:02, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.889000</td>\n",
       "      <td>2.845359</td>\n",
       "      <td>0.195645</td>\n",
       "      <td>0.407772</td>\n",
       "      <td>0.319139</td>\n",
       "      <td>0.407772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.532300</td>\n",
       "      <td>2.025870</td>\n",
       "      <td>0.384281</td>\n",
       "      <td>0.620758</td>\n",
       "      <td>0.564960</td>\n",
       "      <td>0.620758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.837100</td>\n",
       "      <td>1.599020</td>\n",
       "      <td>0.445523</td>\n",
       "      <td>0.677324</td>\n",
       "      <td>0.630073</td>\n",
       "      <td>0.677324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.443000</td>\n",
       "      <td>1.343100</td>\n",
       "      <td>0.492088</td>\n",
       "      <td>0.714707</td>\n",
       "      <td>0.673921</td>\n",
       "      <td>0.714707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.196500</td>\n",
       "      <td>1.178998</td>\n",
       "      <td>0.561928</td>\n",
       "      <td>0.747172</td>\n",
       "      <td>0.719158</td>\n",
       "      <td>0.747172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.066200</td>\n",
       "      <td>1.075744</td>\n",
       "      <td>0.600393</td>\n",
       "      <td>0.767831</td>\n",
       "      <td>0.745497</td>\n",
       "      <td>0.767831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.954600</td>\n",
       "      <td>1.005013</td>\n",
       "      <td>0.637546</td>\n",
       "      <td>0.783079</td>\n",
       "      <td>0.765256</td>\n",
       "      <td>0.783079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.862900</td>\n",
       "      <td>0.957690</td>\n",
       "      <td>0.652921</td>\n",
       "      <td>0.791441</td>\n",
       "      <td>0.776141</td>\n",
       "      <td>0.791441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.786300</td>\n",
       "      <td>0.932236</td>\n",
       "      <td>0.660928</td>\n",
       "      <td>0.794884</td>\n",
       "      <td>0.780569</td>\n",
       "      <td>0.794884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.774300</td>\n",
       "      <td>0.923310</td>\n",
       "      <td>0.665515</td>\n",
       "      <td>0.797344</td>\n",
       "      <td>0.783111</td>\n",
       "      <td>0.797344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1800, training_loss=1.4999479251437717, metrics={'train_runtime': 423.3619, 'train_samples_per_second': 271.966, 'train_steps_per_second': 4.252, 'total_flos': 855487444008960.0, 'train_loss': 1.4999479251437717, 'epoch': 10.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f'./runs/{EXPERIMENT_NAME}',\n",
    "    evaluation_strategy='epoch',\n",
    "    num_train_epochs=N_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    warmup_steps=50,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=f'./logs/{EXPERIMENT_NAME}',\n",
    "    logging_steps=100,\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=LR,\n",
    "    lr_scheduler_type='linear',\n",
    "    # gradient_accumulation_steps=4,\n",
    "    report_to='tensorboard',\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=NUM_CLASSES)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f33a6374-2e9a-4088-a0f1-ae8dc1144031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9444359540939331,\n",
       " 'eval_f1_macro': 0.6738554455602712,\n",
       " 'eval_f1_micro': 0.800605245460659,\n",
       " 'eval_f1_weighted': 0.7898286044286893,\n",
       " 'eval_accuracy': 0.800605245460659,\n",
       " 'eval_runtime': 3.9466,\n",
       " 'eval_samples_per_second': 753.567,\n",
       " 'eval_steps_per_second': 11.909,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(dataset['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1f3d88-2880-4cc0-8787-d2fd4a3c17ab",
   "metadata": {},
   "source": [
    "Baseline метрики для сравнения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd18051-66b4-4ef4-bbd5-6800fe4fcf89",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Distilbert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba86c3bb-cac0-4612-8314-085c22f81a54",
   "metadata": {},
   "source": [
    "Беру DistilBert от DeepPavlov, так как показывает более сильные результаты и по определению лучше tiny варианта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57e628eb-7239-41d4-b6b7-80dfd995c821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d34f7d70-006d-4949-91ac-4c556321144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "roc_auc = evaluate.load(\"roc_auc\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_preds):    \n",
    "    predictions, labels = eval_preds\n",
    "\n",
    "    predictions = predictions[0]\n",
    "\n",
    "    f1_m = f1.compute(predictions=predictions, references=labels, average='macro')[\"f1\"]\n",
    "    f1_micro = f1.compute(predictions=predictions, references=labels, average='micro')[\"f1\"]\n",
    "    f1_w = f1.compute(predictions=predictions, references=labels, average='weighted')[\"f1\"]\n",
    "    \n",
    "    accuracy_m = accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    \n",
    "    return {\"f1_macro\": f1_m,\n",
    "            \"f1_micro\": f1_micro, \n",
    "            \"f1_weighted\": f1_w,\n",
    "            \"accuracy\": accuracy_m}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "584ae383-a904-4555-adc0-9abe165aadde",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "BATCH_SIZE = 16\n",
    "N_EPOCHS = 3\n",
    "MODEL_NAME = 'DeepPavlov/distilrubert-base-cased-conversational'\n",
    "LR = 5e-05\n",
    "EXPERIMENT_NAME = 'better_model'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True, model_max_length=512, truncation=True)#, padding=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0e49277-2750-4fa4-8bb6-51be87e88f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"AmazonScience/massive\", \"ru-RU\").select_columns(['utt', 'intent'])\n",
    "dataset = dataset.rename_column(\"utt\", \"text\")\n",
    "dataset = dataset.rename_column(\"intent\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1869cff-c2aa-4ff8-9425-21ebd9c52d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'] = dataset['train'].map(lambda x: tokenizer(x['text'], truncation=True), batched=True) #Здесь для train не заполняю полностью паддингами, чтобы обучение шло быстрее и меньше памяти использовалось.\n",
    "dataset['validation'] = dataset['validation'].map(lambda x: tokenizer(x['text'], truncation=True, padding='max_length'), batched=True)\n",
    "dataset['test'] = dataset['test'].map(lambda x: tokenizer(x['text'], truncation=True, padding='max_length'), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a3d4529-8f3c-4984-868b-6a303645d402",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = len(dataset[\"train\"].features['label'].names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f584461-4812-4321-adfc-8409146ad160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    pred_ids = torch.argmax(logits[0], axis=1)\n",
    "    return pred_ids, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aae5a753-1f54-4c0b-9f0b-b46f1aa121b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/distilrubert-base-cased-conversational and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2160' max='2160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2160/2160 01:55, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.798800</td>\n",
       "      <td>0.662573</td>\n",
       "      <td>0.739533</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.835812</td>\n",
       "      <td>0.841121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.366800</td>\n",
       "      <td>0.553788</td>\n",
       "      <td>0.804528</td>\n",
       "      <td>0.861289</td>\n",
       "      <td>0.858790</td>\n",
       "      <td>0.861289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.229600</td>\n",
       "      <td>0.544616</td>\n",
       "      <td>0.824277</td>\n",
       "      <td>0.868175</td>\n",
       "      <td>0.866501</td>\n",
       "      <td>0.868175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2160, training_loss=0.8599162375485455, metrics={'train_runtime': 115.3474, 'train_samples_per_second': 299.46, 'train_steps_per_second': 18.726, 'total_flos': 145776281994000.0, 'train_loss': 0.8599162375485455, 'epoch': 3.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f'./runs/{EXPERIMENT_NAME}',\n",
    "    evaluation_strategy='epoch',\n",
    "    num_train_epochs=N_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    warmup_steps=250,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=f'./logs/{EXPERIMENT_NAME}',\n",
    "    logging_steps=100,\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=LR,\n",
    "    lr_scheduler_type='linear',\n",
    "    eval_accumulation_steps=10,\n",
    "    report_to='tensorboard',\n",
    "    seed=SEED)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=NUM_CLASSES)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics # otherwise - cuda out of memory because of compute_metrics saves all output logits\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d31ce8-b81a-48dc-b57a-8595fb0d2d1f",
   "metadata": {},
   "source": [
    "Метрики по сравнению с меньшей моделью ощутимо лучше при меньшем кол-ве эпох"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5860ade-f3fd-4b4e-b199-4ae0f20d62ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='186' max='186' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [186/186 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5236570835113525,\n",
       " 'eval_f1_macro': 0.8160391550149407,\n",
       " 'eval_f1_micro': 0.87457969065232,\n",
       " 'eval_f1_weighted': 0.8732484844599534,\n",
       " 'eval_accuracy': 0.8745796906523201,\n",
       " 'eval_runtime': 15.6681,\n",
       " 'eval_samples_per_second': 189.812,\n",
       " 'eval_steps_per_second': 11.871,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269645b9-13eb-4a63-abbf-bf808b88e895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline\n",
    "# {'eval_loss': 0.94443,\n",
    "#  'eval_f1_macro': 0.6738554455602712,\n",
    "#  'eval_f1_micro': 0.800605245460659,\n",
    "#  'eval_f1_weighted': 0.7898286044286893,\n",
    "#  'eval_accuracy': 0.800605245460659,\n",
    "#  'eval_runtime': 3.9466,\n",
    "#  'eval_samples_per_second': 753.567,\n",
    "#  'eval_steps_per_second': 11.909,\n",
    "#  'epoch': 10.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db61ea82-9c14-40b5-a68c-5bcb80707005",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# OOD Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a64d3c-0ea2-464c-bc85-3b8e3bc9adbc",
   "metadata": {},
   "source": [
    "Здесь есть несколько подходов к решению задачи:  \n",
    "1. Использование методов, не требующих ood выборки\n",
    "2. Использование архитектур с использованием ood сэмплов\n",
    "\n",
    "Базово взял датасет коротких отзывов с Кинопоиска, который будет играть роль ood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce15d43a-f713-4d51-aaf7-8dfdca479e73",
   "metadata": {},
   "source": [
    "Также тут использовал pytorch_ood, в которой реализованы базовые методы, которые правда также пришлось патчить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77c008db-4cd3-446b-bc3a-9f86e99f9762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch\n",
    "from pytorch_ood.detector import (\n",
    " EnergyBased,\n",
    " Entropy,\n",
    " MaxLogit,\n",
    " MaxSoftmax)\n",
    "\n",
    "from pytorch_ood.utils import OODMetrics\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cab13dc2-38b0-471b-b5d5-0c2347557a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"AmazonScience/massive\", \"ru-RU\").select_columns(['utt', 'intent'])\n",
    "dataset = dataset.rename_column(\"utt\", \"text\")\n",
    "dataset = dataset.rename_column(\"intent\", \"label\")\n",
    "NUM_CLASSES = len(dataset[\"train\"].features['label'].names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "821fd8da-1225-4fd5-99d0-9167f515729f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('runs/better_model/checkpoint-2160/', num_labels=NUM_CLASSES).to('cuda')\n",
    "tokenizer = AutoTokenizer.from_pretrained('runs/better_model/checkpoint-2160/', use_fast=True, model_max_length=512, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4666f9e6-611b-4d69-9684-12810ec6d597",
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_dataset = load_dataset(\"zloelias/kinopoisk-reviews-short\")\n",
    "ood_dataset = concatenate_datasets([ood_dataset['train'], ood_dataset['test']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a402d4ed-34f2-4086-a258-052afd97cd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentDataset(Dataset):\n",
    "    def __init__(self, text, labels):\n",
    "        self.labels = labels\n",
    "        self.text = text\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return {\"text\": self.text[idx], \"label\": self.labels[idx]}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b49e8c1a-0a59-4818-b02d-e804f2e6a9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_dataset = IntentDataset(ood_dataset['text']+dataset['validation']['text'], [-1]*ood_dataset.shape[0]+dataset['validation']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01ac8d8f-b7ee-4f11-a6ff-c401cf5c0cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    txt = []\n",
    "    labels = []\n",
    "    for elem in batch:\n",
    "        txt.append(elem['text'])\n",
    "        labels.append(elem['label'])\n",
    "    tokens = tokenizer(txt, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "    tokens['labels'] = torch.tensor(labels)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6564b3-4914-485a-a16d-06376b4dc8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_dataloader = DataLoader(ood_dataset, batch_size=64, collate_fn=collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0058f6a1-64e1-4e8c-abaa-e8a4ac336eb2",
   "metadata": {},
   "source": [
    "Взял 4 базовых алгоритма для ood detection. Самые главные метрики - AUCROC и FPR95TPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0188a0f-d9ce-4713-a271-1bec76b27b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_ood.utils import TensorBuffer, contains_unknown, extract_features, is_known, is_unknown\n",
    "\n",
    "\n",
    "class MaxSoftmaxPatched(MaxSoftmax):\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        :param x: input, will be passed through model\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ModelNotSetException\n",
    "\n",
    "        return self.predict_features(self.model(**x).logits)\n",
    "\n",
    "class EntropyPatched(Entropy):\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        :param x: input, will be passed through model\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ModelNotSetException\n",
    "\n",
    "        return self.predict_features(self.model(**x).logits)\n",
    "\n",
    "\n",
    "class MaxLogitPatched(MaxLogit):\n",
    "    \"\"\"\n",
    "    Implements the Max Logit Method for OOD Detection as proposed in\n",
    "    *Scaling Out-of-Distribution Detection for Real-World Settings*.\n",
    "\n",
    "    .. math:: - \\\\max_y f_y(x)\n",
    "\n",
    "    where :math:`f_y(x)` indicates the :math:`y^{th}` logits value predicted by :math:`f`.\n",
    "\n",
    "    :see Paper:\n",
    "       `ArXiv <https://.org/abs/1911.11132>`__\n",
    "    \"\"\"\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        :param x:  model inputs\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ModelNotSetException\n",
    "\n",
    "        return self.score(self.model(**x).logits)\n",
    "\n",
    "    def predict_features(self, logits):\n",
    "        \"\"\"\n",
    "        :param logits: logits as given by the model\n",
    "        \"\"\"\n",
    "        return MaxLogit.score(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5bac724-9888-4c82-a091-51f74bbdac53",
   "metadata": {},
   "outputs": [],
   "source": [
    " detectors = {}\n",
    " detectors[\"Entropy\"] = EntropyPatched(model)\n",
    " detectors[\"MaxSoftmax\"] = MaxSoftmaxPatched(model)\n",
    " detectors[\"EnergyBased\"] = EnergyBased(model)\n",
    " detectors[\"MaxLogit\"] = MaxLogitPatched(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f665edb3-fe3a-4fa1-ace4-95468f6a3d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e246de445a5d4618b990799259ce3ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e104ae0958804ba1bc2012aad7f730d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d5027bf24244ba8b74c0b7acdb6e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef443727c2a4d8ba9fc82110664dc35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUPR-IN</th>\n",
       "      <th>AUPR-OUT</th>\n",
       "      <th>FPR95TPR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Detector</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Entropy</th>\n",
       "      <td>0.938603</td>\n",
       "      <td>0.609260</td>\n",
       "      <td>0.990207</td>\n",
       "      <td>0.166749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxSoftmax</th>\n",
       "      <td>0.913679</td>\n",
       "      <td>0.496736</td>\n",
       "      <td>0.986319</td>\n",
       "      <td>0.192818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EnergyBased</th>\n",
       "      <td>0.949726</td>\n",
       "      <td>0.592015</td>\n",
       "      <td>0.992306</td>\n",
       "      <td>0.121495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxLogit</th>\n",
       "      <td>0.943573</td>\n",
       "      <td>0.574736</td>\n",
       "      <td>0.991304</td>\n",
       "      <td>0.133792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                AUROC   AUPR-IN  AUPR-OUT  FPR95TPR\n",
       "Detector                                           \n",
       "Entropy      0.938603  0.609260  0.990207  0.166749\n",
       "MaxSoftmax   0.913679  0.496736  0.986319  0.192818\n",
       "EnergyBased  0.949726  0.592015  0.992306  0.121495\n",
       "MaxLogit     0.943573  0.574736  0.991304  0.133792"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "with torch.no_grad():\n",
    "    for detector_name, detector in detectors.items():\n",
    "        metrics = OODMetrics()\n",
    "        for batch in tqdm(ood_dataloader):\n",
    "            y = batch.pop('labels')\n",
    "            for k in batch:\n",
    "                batch[k] = batch[k].to('cuda')\n",
    "            r = {\"Detector\": detector_name}\n",
    "            metrics.update(detector(batch), y)\n",
    "            r.update(metrics.compute())\n",
    "        results.append(r)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.index = df['Detector']\n",
    "df = df.drop(['Detector'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3641b746-93ee-414d-b484-bf07f0088f9f",
   "metadata": {},
   "source": [
    "AUC-ROC и FPR95TPR получились неплохим, но есть куда улучшаться. В даном случае EnergyBased показал себя лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e926f752-665b-445d-ae33-a3bede707cc6",
   "metadata": {},
   "source": [
    "# Обучение BERT с Contrastive loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b22e32-ba68-47bd-9f3b-de05c7b62f7a",
   "metadata": {},
   "source": [
    "Взял по статье: Contrastive Out-of-Distribution Detection for Pretrained Transformers  \n",
    "https://arxiv.org/abs/2104.08812"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fc8788-0076-4883-8b06-4507cd0473c9",
   "metadata": {},
   "source": [
    "За основу взял их выложенный код с некоторыми изменениями под пайплайн и задачу. Адаптировал код под DistilBert, используемый выше и под датасет.  \n",
    "  \n",
    "В целом из-за contrastive loss могут подрасти метрики, но главное здесь - более\n",
    "выраженное ood detection за счет того, что классы будут ближе друг к другу в эмбеддинговом пространстве и поэтому любые ood примеры будут сильнее от них отличаться, что даст лучшую возможность для их детекции.\n",
    "\n",
    "По статье авторов, alpha вес const. loss - 2 лучше себя показал. Также как и margin loss. Сразу использую их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9cb5766-e218-4c4b-a84f-74c0711a6ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification, DistilBertModel, DistilBertConfig\n",
    "import torch\n",
    "from src.dataset import load_intent_dataset, load_ood_dataset\n",
    "from src.train_utils import train, validation\n",
    "from torch.utils.data import DataLoader\n",
    "from contrastive.utils import set_seed\n",
    "from contrastive.model import DistilBertForSequenceClassification\n",
    "import random\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "LR = 1e-5\n",
    "ADAM_EPS = 1e-6\n",
    "WARMUP_RATIO = 0.06\n",
    "WEIGHT_DECAY = 0.01\n",
    "NUM_EPOCHES = 10\n",
    "SEED = 42\n",
    "PROJECT_NAME = 'BERT_contrastive'\n",
    "ALPHA = 2\n",
    "LOSS = 'margin'\n",
    "MODEL_NAME = 'DeepPavlov/distilrubert-base-cased-conversational'\n",
    "DROPOUT = 0.2\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b91aba61-e231-498e-bd2a-0ac1b2a3c080",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    txt = []\n",
    "    labels = []\n",
    "    for elem in batch:\n",
    "        txt.append(elem['text'])\n",
    "        labels.append(elem['label'])\n",
    "    tokens = tokenizer(txt, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "    tokens['labels'] = torch.tensor(labels)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def collate_fn_val(batch):\n",
    "    txt = []\n",
    "    labels = []\n",
    "    for elem in batch:\n",
    "        txt.append(elem['text'])\n",
    "        labels.append(elem['label'])\n",
    "    tokens = tokenizer(txt, max_length=512, padding='max_length', truncation=True, return_tensors='pt')\n",
    "    tokens['labels'] = torch.tensor(labels)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def collate_fn_ood(batch):\n",
    "    txt = []\n",
    "    labels = []\n",
    "    for elem in batch:\n",
    "        txt.append(elem['text'])\n",
    "        labels.append(elem['labels'])\n",
    "    tokens = tokenizer(txt, max_length=512, padding='max_length', truncation=True, return_tensors='pt')\n",
    "    tokens['labels'] = torch.tensor(labels)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81b4d8ab-fd23-4b07-8591-9e8a3118d298",
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_dataset = load_dataset(\"zloelias/kinopoisk-reviews-short\")\n",
    "ood_dataset = concatenate_datasets([ood_dataset['train'], ood_dataset['test']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6a62d15-b24b-427d-8854-e9c6d32714f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_intent_dataset()\n",
    "NUM_CLASSES = len(dataset[\"train\"].features['label'].names)\n",
    "\n",
    "train_dataloader = DataLoader(dataset['train'], batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=True, drop_last=True)\n",
    "val_dataloader = DataLoader(dataset['validation'], batch_size=BATCH_SIZE, collate_fn=collate_fn_val)\n",
    "test_dataloader = DataLoader(dataset['test'], batch_size=BATCH_SIZE, collate_fn=collate_fn_val)\n",
    "ood_dataloader = DataLoader(ood_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn_ood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6cdc92b-390e-4c55-aeec-0989d68c5d9a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (bert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=60, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = DistilBertConfig.from_pretrained(MODEL_NAME)\n",
    "config.gradient_checkpointing = True\n",
    "config.alpha = ALPHA\n",
    "config.loss = 'margin'\n",
    "config.dropout = DROPOUT\n",
    "config.num_labels = NUM_CLASSES\n",
    "config.num_epoches = NUM_EPOCHES\n",
    "config.warmup_ratio = WARMUP_RATIO\n",
    "config.weight_decay = WEIGHT_DECAY\n",
    "config.adam_eps = ADAM_EPS\n",
    "config.project_name = PROJECT_NAME\n",
    "config.lr = LR\n",
    "config.device = device\n",
    "distilbert = DistilBertModel.from_pretrained(MODEL_NAME, config=config)\n",
    "model = DistilBertForSequenceClassification(distilbert, config=config)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11814ce3-b199-4220-bcd7-5f5477b27532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b219b076699c4abd9a17e1bb856de0f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/719 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd923b67f73e4119bdddea868f8a8bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_macro': 0.48686571968731784, 'f1_micro': 0.706837186424004, 'f1_weighted': 0.6656988749480022, 'accuracy': 0.706837186424004}\n",
      "{'softmax_auroc': 0.9791129293486738, 'softmax_fpr95': 0.1524390243902439, 'maha_auroc': 0.9998950247741534, 'maha_fpr95': 0.0, 'cosine_auroc': 0.9947707341067509, 'cosine_fpr95': 0.024390243902439025, 'energy_auroc': 0.9974386044893406, 'energy_fpr95': 0.009146341463414634}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd2d45e37ea4493b5bc013931cae8b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/719 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "055f2288fba546bb886f185afb0c3954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_macro': 0.728629349783331, 'f1_micro': 0.8312838170191835, 'f1_weighted': 0.8227912256832668, 'accuracy': 0.8312838170191835}\n",
      "{'softmax_auroc': 0.9720405984187731, 'softmax_fpr95': 0.14939024390243902, 'maha_auroc': 0.9997705541492208, 'maha_fpr95': 0.0, 'cosine_auroc': 0.9950751622617061, 'cosine_fpr95': 0.009146341463414634, 'energy_auroc': 0.9958504792868883, 'energy_fpr95': 0.021341463414634148}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44e992b735942e2bfde505a409dd074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/719 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb40959baa446d49f8fa2537ba3cfb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_macro': 0.7725456157038892, 'f1_micro': 0.8519429414658142, 'f1_weighted': 0.8469057575354835, 'accuracy': 0.8519429414658141}\n",
      "{'softmax_auroc': 0.9552085707772966, 'softmax_fpr95': 0.2652439024390244, 'maha_auroc': 0.9992201840365673, 'maha_fpr95': 0.0, 'cosine_auroc': 0.9926772281741509, 'cosine_fpr95': 0.021341463414634148, 'energy_auroc': 0.9920218828356507, 'energy_fpr95': 0.036585365853658534}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5279c45d3830483bb6debb73f040bfbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/719 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "331ea13836ec428b85c92e83863ad4e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_macro': 0.8047646030800135, 'f1_micro': 0.8588293162813576, 'f1_weighted': 0.8565526280204548, 'accuracy': 0.8588293162813576}\n",
      "{'softmax_auroc': 0.9422921190599018, 'softmax_fpr95': 0.3475609756097561, 'maha_auroc': 0.9992246829748179, 'maha_fpr95': 0.0, 'cosine_auroc': 0.9929606612839369, 'cosine_fpr95': 0.006097560975609756, 'energy_auroc': 0.9886626756085563, 'energy_fpr95': 0.054878048780487805}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d70331c7ce43a289b1a552c79064b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/719 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c21f306d1a5f4957a63a0779bc10e4ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_macro': 0.8115677282892438, 'f1_micro': 0.8642400393507131, 'f1_weighted': 0.8624121894993196, 'accuracy': 0.8642400393507133}\n",
      "{'softmax_auroc': 0.941986191258863, 'softmax_fpr95': 0.3628048780487805, 'maha_auroc': 0.9985393447146473, 'maha_fpr95': 0.0, 'cosine_auroc': 0.9907171907429847, 'cosine_fpr95': 0.018292682926829267, 'energy_auroc': 0.9875169460007438, 'energy_fpr95': 0.06097560975609756}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4235aebd8314400a9214ff2961f812d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/719 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34e373e19ff04b8fa3918f0699ca076a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_macro': 0.8196905014441422, 'f1_micro': 0.867683226758485, 'f1_weighted': 0.8660591072901017, 'accuracy': 0.867683226758485}\n",
      "{'softmax_auroc': 0.9481512363082312, 'softmax_fpr95': 0.3201219512195122, 'maha_auroc': 0.9988122803018488, 'maha_fpr95': 0.0, 'cosine_auroc': 0.9914265233404915, 'cosine_fpr95': 0.009146341463414634, 'energy_auroc': 0.9900078581454776, 'energy_fpr95': 0.051829268292682924}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239bec4bac124fceb6bf128470fa7fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/719 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e8da34bb21c499abe28d1c968258446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_macro': 0.8118827417009223, 'f1_micro': 0.8622725036891293, 'f1_weighted': 0.85981428551322, 'accuracy': 0.8622725036891293}\n",
      "{'softmax_auroc': 0.9463516610080022, 'softmax_fpr95': 0.3353658536585366, 'maha_auroc': 0.9987702902115101, 'maha_fpr95': 0.0, 'cosine_auroc': 0.991198577135796, 'cosine_fpr95': 0.018292682926829267, 'energy_auroc': 0.9875799311362518, 'energy_fpr95': 0.06402439024390244}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f84d12687d243f3b363e7ce1e7e13b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/719 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe16e721703641abb0373400a77c5744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_macro': 0.8267078717267127, 'f1_micro': 0.8652238071815052, 'f1_weighted': 0.863718435034869, 'accuracy': 0.8652238071815052}\n",
      "{'softmax_auroc': 0.938877424927717, 'softmax_fpr95': 0.3902439024390244, 'maha_auroc': 0.9984133744436312, 'maha_fpr95': 0.0, 'cosine_auroc': 0.9905507300277134, 'cosine_fpr95': 0.021341463414634148, 'energy_auroc': 0.9857758568977721, 'energy_fpr95': 0.0701219512195122}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed0664dee87443ce890ec27aaafa779b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/719 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5def46d19704334a4d1a83f97a8d10b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_macro': 0.8262154680158195, 'f1_micro': 0.8647319232661091, 'f1_weighted': 0.8628759409719879, 'accuracy': 0.8647319232661091}\n",
      "{'softmax_auroc': 0.9473309299005436, 'softmax_fpr95': 0.32926829268292684, 'maha_auroc': 0.9983578875385409, 'maha_fpr95': 0.0, 'cosine_auroc': 0.9898039062781183, 'cosine_fpr95': 0.024390243902439025, 'energy_auroc': 0.9877613883123582, 'energy_fpr95': 0.06402439024390244}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54613d963dd34f5f82b83af22dfdb307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/719 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb5dbc27dd14c518e5e152fbfb1af97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_macro': 0.8278669359417569, 'f1_micro': 0.8647319232661091, 'f1_weighted': 0.8632588087105029, 'accuracy': 0.8647319232661091}\n",
      "{'softmax_auroc': 0.9428889782011445, 'softmax_fpr95': 0.3567073170731707, 'maha_auroc': 0.9982604105431118, 'maha_fpr95': 0.0, 'cosine_auroc': 0.9896689381306011, 'cosine_fpr95': 0.021341463414634148, 'energy_auroc': 0.9865451753386202, 'energy_fpr95': 0.06707317073170732}\n"
     ]
    }
   ],
   "source": [
    "train(model, train_dataloader, val_dataloader, test_dataloader, ood_dataloader, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eec4840-5924-4b8e-a04f-7287172c684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(\"runs/BERT_contrastive/checkpoint-7190/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e145254-e931-487c-9bda-49154a8385a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('runs/BERT_contrastive/checkpoint-7190/model.pt', map_location='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9242f1d-635b-4b9f-803a-cf6115454de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b2fd274a3d4ad29c2d43e24775eecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/186 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'f1_macro': 0.8325511550133567,\n",
       " 'f1_micro': 0.8742434431741762,\n",
       " 'f1_weighted': 0.8730034632488446,\n",
       " 'accuracy': 0.8742434431741762}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation(model, test_dataloader, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c69aa4-07c7-4cb5-9cc6-dfd7fb561b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'eval_loss': 0.5236570835113525,\n",
    "#  'eval_f1_macro': 0.8160391550149407,\n",
    "#  'eval_f1_micro': 0.87457969065232,\n",
    "#  'eval_f1_weighted': 0.8732484844599534,\n",
    "#  'eval_accuracy': 0.8745796906523201,\n",
    "#  'eval_runtime': 15.6681,\n",
    "#  'eval_samples_per_second': 189.812,\n",
    "#  'eval_steps_per_second': 11.871,\n",
    "#  'epoch': 3.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2427a5-2c11-47c2-a589-8ae9454eef38",
   "metadata": {},
   "source": [
    "Как и ожидалось по aucroc и fpr95tpr Mahalanobis показал сильно лучшие результаты над предыдущей моделью."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a669b7c-663d-4f1b-84ea-b3279bf1c184",
   "metadata": {},
   "source": [
    "Из выбранных детекторов лучше всего показывает Mahalanobis distance, что является вполне закономерным, так как и ранее в статьях показывалось, что для эмбеддингов трансформеров измерение такого расстояния дает лучшие результаты  \n",
    "по обнаружению ood примеров. Метрики же остались сопоставимыми с предыдущим вариантом без Contrastive loss.\n",
    "\n",
    "\n",
    "Остановлюсь на данной модели и на Mahalanobis distance для ood, теперь нужно получить лучший threshold, по которому будут отделяться ood от in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddd72c1c-05f6-4cd6-af64-0b1ba9ca3434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_threshold(model, dataloader, ood, config):\n",
    "    keys = ['maha']\n",
    "\n",
    "    in_scores = []\n",
    "    for batch in dataloader:\n",
    "        model.eval()\n",
    "        batch = {key: value.to(config.device) for key, value in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            ood_keys = model.compute_ood(**batch)\n",
    "            in_scores.append(ood_keys)\n",
    "    in_scores = merge_keys(in_scores, keys)\n",
    "\n",
    "    out_scores = []\n",
    "    for batch in ood:\n",
    "        model.eval()\n",
    "        batch = {key: value.to(config.device) for key, value in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            ood_keys = model.compute_ood(**batch)\n",
    "            out_scores.append(ood_keys)\n",
    "    out_scores = merge_keys(out_scores, keys)\n",
    "\n",
    "    outputs = {}\n",
    "    for key in keys:\n",
    "        ins = np.array(in_scores[key], dtype=np.float64)\n",
    "        outs = np.array(out_scores[key], dtype=np.float64)\n",
    "        inl = np.ones_like(ins).astype(np.int64)\n",
    "        outl = np.zeros_like(outs).astype(np.int64)\n",
    "        scores = np.concatenate([ins, outs], axis=0)\n",
    "        labels = np.concatenate([inl, outl], axis=0)\n",
    "        \n",
    "        return scores, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05e863fe-08a0-4876-b28e-e9e48848610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train_utils import merge_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6de69250-912f-4ae5-933d-448fcc84a9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, labels = get_optimal_threshold(model, test_dataloader, ood_dataloader, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22e4bd42-ac88-44b6-9c42-4316b82856a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - in, 0 - out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fc77f20-28d3-4556-9403-d6e2b24a3a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(labels, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c816be4-f72d-4b11-9ca3-78b6dec321b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5944b932-c4af-468c-8400-940e79d060db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd935914a90>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6841208-a0ef-452f-a7fd-f08ff7be9296",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_proba_cutoff = sorted(list(zip(np.abs(tpr - fpr), thresholds)), key=lambda i: i[0], reverse=True)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "343b7d8c-40e7-4211-9bc5-e0c984a69a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3951.605712890625"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_proba_cutoff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c992419b-0ff6-4d6e-a8b3-a8f038004883",
   "metadata": {},
   "source": [
    "В целом здесь еще необходимо покопаться в конкретных классах, так как метрики смотрел в целом по интентам и смотреть где сильно может проседать классификатор. Также лучше бы иметь более близкий датасет, возможно с теми  \n",
    "\n",
    "интентами, которые не реализованы в голосовом помощнике для более точечного отделения ood. Также здесь довольно большое поле для экспериментов, те статьи, которые я почитал на данную тему предлагают довольно большой пласт  \n",
    "вариантов обучения модели как с ood, так и без него, как в реализованном выше варианте, но я остановился на данном варианте из-за отсутствия ood.  \n",
    "\n",
    "А так, это конечно только часть из необходимых экспериментов и проверки гипотез, так как иначе тестовое задание не будет иметь конца :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mts",
   "language": "python",
   "name": "mts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
